{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2609a5-3691-4c2f-b187-7a2452f6b3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas numpy matplotlib seaborn scikit-learn xgboost joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683a1cbe-8a92-4c16-b560-d18f63880717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================\n",
    "# WATER POTABILITY PREDICTION - COMPLETE SCRIPT\n",
    "# =============================================\n",
    "\n",
    "# --------------------------\n",
    "# 1. Import Required Libraries\n",
    "# --------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import joblib\n",
    "\n",
    "# --------------------------\n",
    "# 2. Load and Explore Data\n",
    "# --------------------------\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"water_quality.csv\")\n",
    "\n",
    "# Display basic info\n",
    "print(\"\\n=== Data Overview ===\")\n",
    "print(\"First 5 rows:\\n\", df.head())  # Check column names and sample data\n",
    "print(\"\\nData shape:\", df.shape)     # Verify row/column count\n",
    "print(\"\\nData types:\\n\", df.dtypes)  # Check for any unexpected data types\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(df.isnull().sum())  # If any, handle with df.fillna() or df.dropna()\n",
    "\n",
    "# Analyze target variable distribution\n",
    "print(\"\\nPotability class distribution:\")\n",
    "print(df[\"Potability\"].value_counts())  # Note: Imbalanced (61% vs 39%)\n",
    "\n",
    "# --------------------------\n",
    "# 3. Data Visualization (EDA)\n",
    "# --------------------------\n",
    "# Set style for plots\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Plot 1: Target class distribution\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(x=\"Potability\", data=df)\n",
    "plt.title(\"Potability Class Distribution (0=Not Potable, 1=Potable)\")\n",
    "plt.show()\n",
    "\n",
    "# Plot 2: Boxplot for key numerical features\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x=\"Potability\", y=\"Solids\", data=df)\n",
    "plt.title(\"Solids Distribution by Potability Status\")\n",
    "plt.show()\n",
    "\n",
    "# Plot 3: Correlation heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "corr_matrix = df.corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\", center=0)\n",
    "plt.title(\"Feature Correlation Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# --------------------------\n",
    "# 4. Feature Engineering\n",
    "# --------------------------\n",
    "# Drop highly correlated features (if any)\n",
    "df = df.drop(\"log_Solids\", axis=1)  # log_Solids and Solids are 99% correlated\n",
    "\n",
    "# One-hot encode categorical features (example)\n",
    "if \"Solids_bins\" in df.columns:\n",
    "    df = pd.get_dummies(df, columns=[\"Solids_bins\"], drop_first=True)\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "X = df.drop(\"Potability\", axis=1)\n",
    "y = df[\"Potability\"]\n",
    "\n",
    "# Split into training (80%) and testing (20%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Standardize features (important for models like SVM, Logistic Regression)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)  # Fit on training data only\n",
    "X_test_scaled = scaler.transform(X_test)        # Transform test data\n",
    "\n",
    "# --------------------------\n",
    "# 5. Model Building\n",
    "# --------------------------\n",
    "# Initialize models with class weighting for imbalance handling\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(class_weight=\"balanced\", random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(\n",
    "        class_weight=\"balanced_subsample\", random_state=42\n",
    "    ),\n",
    "    \"XGBoost\": XGBClassifier(\n",
    "        scale_pos_weight=sum(y == 0) / sum(y == 1),  # Handle imbalance\n",
    "        eval_metric=\"logloss\",\n",
    "        random_state=42,\n",
    "    ),\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n=== Training {name} ===\")\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    # Evaluation metrics\n",
    "    print(f\"\\n{name} Performance:\")\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# --------------------------\n",
    "# 6. Model Optimization (Hyperparameter Tuning)\n",
    "# --------------------------\n",
    "# Focus on the best-performing model (Random Forest in this case)\n",
    "print(\"\\n=== Hyperparameter Tuning for Random Forest ===\")\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    \"n_estimators\": [100, 200],      # Number of trees\n",
    "    \"max_depth\": [None, 10, 20],     # Maximum tree depth\n",
    "    \"min_samples_split\": [2, 5],     # Minimum samples to split a node\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "rf = RandomForestClassifier(class_weight=\"balanced_subsample\", random_state=42)\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,               # 5-fold cross-validation\n",
    "    scoring=\"f1\",       # Optimize for F1-score (balance of precision/recall)\n",
    "    n_jobs=-1           # Use all CPU cores\n",
    ")\n",
    "\n",
    "# Execute grid search\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Results\n",
    "print(\"\\nBest Parameters:\", grid_search.best_params_)\n",
    "print(\"Best F1-Score:\", grid_search.best_score_)\n",
    "\n",
    "# Get optimized model\n",
    "optimized_rf = grid_search.best_estimator_\n",
    "\n",
    "# Final evaluation\n",
    "y_pred_optimized = optimized_rf.predict(X_test_scaled)\n",
    "print(\"\\nOptimized Model Performance:\")\n",
    "print(classification_report(y_test, y_pred_optimized))\n",
    "\n",
    "# --------------------------\n",
    "# 7. Feature Importance Analysis\n",
    "# --------------------------\n",
    "# Get feature importances from the optimized model\n",
    "importances = optimized_rf.feature_importances_\n",
    "feature_importance = pd.DataFrame(\n",
    "    {\"Feature\": X.columns, \"Importance\": importances}\n",
    ").sort_values(\"Importance\", ascending=False)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=\"Importance\", y=\"Feature\", data=feature_importance)\n",
    "plt.title(\"Top Features Influencing Water Potability\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --------------------------\n",
    "# 8. Save the Model for Deployment\n",
    "# --------------------------\n",
    "# Save the trained model and scaler\n",
    "joblib.dump(optimized_rf, \"water_potability_model.pkl\")\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "\n",
    "print(\"\\nModel and scaler saved successfully!\")\n",
    "\n",
    "# =============================================\n",
    "# HOW TO USE THE SAVED MODEL (EXAMPLE)\n",
    "# =============================================\n",
    "\"\"\"\n",
    "# Load the model and scaler\n",
    "loaded_model = joblib.load(\"water_potability_model.pkl\")\n",
    "loaded_scaler = joblib.load(\"scaler.pkl\")\n",
    "\n",
    "# Prepare new sample data (must match original features)\n",
    "new_sample = pd.DataFrame({\n",
    "    \"Hardness\": [204.89],\n",
    "    \"Solids\": [20791.31],\n",
    "    \"Chloramines\": [7.30],\n",
    "    # ... include all other features ...\n",
    "})\n",
    "\n",
    "# Preprocess and predict\n",
    "new_sample_scaled = loaded_scaler.transform(new_sample)\n",
    "prediction = loaded_model.predict(new_sample_scaled)\n",
    "print(\"Potable\" if prediction[0] == 1 else \"Not Potable\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b838e764-0322-4db8-b2a2-d990cf16cd54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388461da-daf3-439d-aa76-25466e96a986",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
